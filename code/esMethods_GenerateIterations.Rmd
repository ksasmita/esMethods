---
title: "esMethods_GenerateIterations"
author: "Karen Sasmita"
date: "4/27/2020"
output: html_document
---

```{r libraryLoad}
library(dplyr)
library(ggplot2)
rm(list = ls())
source("get.esMethods.metrices.r")
```

Define function for plotting 
```{r plotting themes}
#Set text size and colors
txt.size = 12
txt.color = "black"
txt.face = "bold"

###define specs for agreement values plots over sample sizes
#agreement value colors
d.color = "#FFC700" #actual data 
random.color = "#00B885" #random data
crossMov.color = "#4D4D4D" #agreement values when actual data compared to cross movie.
factor.order <- c('crossMov', 'random', 'sample')
factor.color <- c(crossMov.color, random.color, d.color)
factor.shape <- c(24, 23, 21) #triangle, diamond, circle
#jitter for individual agreement values
jitter.alpha = .1 
jitter.width = 0.2
#point for mean agreement value 
point.size = 5
point.alpha = 1
#errorbar width 
errorbar.width = .8
errorbar.alpha = 1

###define specs for saving agreement and function fit plots
figure.width = 25
figure.height = 19 
figure.unit = "cm"
figure.bg = "transparent"
figure.filetype = "png"

grain.labs <- c("Coarse", "Fine")
names(grain.labs) <- c("c", "f")


#Set theme for plotting 
theme.esMethods <- theme(
panel.grid.minor = element_blank(), 
panel.grid.major = element_blank(), 
#panel.background= element_blank(), 
panel.border = element_blank(),
panel.spacing = unit(.05,'in'), 
panel.background = element_rect(fill = "transparent",colour = NA),
plot.background = element_rect(fill = "transparent",colour = NA),
axis.line = element_line(size = .2, colour = "black"), 
axis.title = element_text(size = txt.size),
axis.text = element_text(size = txt.size),
strip.background = element_rect(colour = NA, fill = "transparent"), 
strip.text = element_text(size = txt.size), 
legend.title = element_blank(),
legend.key = element_rect(colour = NA, fill = NA),
plot.title = element_text(hjust = 0.5)
)

```

Define function: plotAgreementValues 
To plot agreement values over sample size 

Parameter df: data frame to pull data for plots from 

Precondition df: data frame 

Parameter var: variable name in data frame to plot (y-values)

Precondition var: string 

Parameter ylab: label for y-axis 

Precondition ylab: string 
```{r defineFunction_plotAgreementValues}
plotAgreementValues <- function(df, var, ylab){
  factors <- factor.order[(length(unique(df$testCond))%%3):3]
  factor.colors <- factor.color[(length(unique(df$testCond))%%3):3]
  factor.shapes <- factor.shape[(length(unique(df$testCond))%%3):3]
  transform(df, testCond=factor(testCond,levels=factors))
  
    figure <- ggplot(df, aes(x = sampleSize, y = get(var, df), fill = testCond, color = testCond, shape = testCond))+
    geom_jitter(alpha = jitter.alpha, width = jitter.width)+
    stat_summary(geom = "errorbar", fun.data = "mean_cl_normal", width = errorbar.width, color = 'black', alpha = errorbar.alpha)+
    geom_point(stat = "summary", fun = "mean", size = point.size, alpha = point.alpha, color = 'black')+
    scale_fill_manual(values = factor.colors)+
    scale_color_manual(values = factor.colors)+
    scale_shape_manual(values = factor.shapes)+
    facet_wrap(~grain, scales='fixed', labeller = labeller(grain = c("c" = "Coarse", "f" = "Fine")))+
    # geom_text(color = 'black', x = 6, y = -.2, label = "+", size = txt.size, show.legend = FALSE)+
    labs(y = ylab, x = "Sample Size")+
    #ylim(-1,2)+
    theme.esMethods
    #assign(paste('figure.', g, sep = ''), figure)`
    #ggsave(paste(paste('figure.', g, sep = ''), ".png", sep = ""))
    
    return(figure)
}
```

Define parameters for bootstrapping, values are the same for commercial and every activity movies. Change these values for different number of iterations and sample sizes. 
```{r defineParameters}      
n.iterations = 10
sampleSize.min = 2
sampleSize.max = 32
sampleSize.interval = 2
```

Define function to extract sample datasets. For every sample size, participants' data were randomly sampled with replacement. The resultant sub-sample may therefore, contain multiple copies of data from the same participant. The following function ensures that every duplicated dataset gets treated independently in subsequent analysis by adding an additional index for every dataset (newid). Therefore, for a sample size of 10, the sampled data will comprise of data with newid 1 - 10. This will also add a new variable: a "random" segmentation data. This new variable is created by:
1. For button press times: randomly generating n number from a uniform distribution with a min value of 0 and max value of movie duration, where n = total number of button press for every individual. 
2. Timeseries of presence/absence of button press: reordering every individual's timeseries. 

Parameter subids: array of subject ids for loading data 

Precondition subid: array 

Parameter dataset: dataframe to pull subset of data from 

Precondition dataset: dataframe 

Parameter randomiseVariable: which type of participant data (bpTime or presence/absence of bp every 1 second)

Precondition randomiseVariable: string ("bpTime" or "bpPresence")

Parameter mov.dur: movie duration (s)

Precondition mov.dur: numeric 

```{r essentialFunctions}
get.sample.dataset = function(subids, dataset, randomiseVariable, mov.dur){
  data.df <- data.frame()
  for(i in 1:length(subids)){
    id.index <- subids[i]
    if (randomiseVariable == "bpTime"){
      sample.id <- dplyr::filter(dataset, subid %in% id.index) %>%  dplyr::filter(bpTime < mov.dur) %>%  dplyr::group_by(grain, movieName) %>%  dplyr::mutate(bpTime.rand = runif(n(), 0, mov.dur)) %>% ungroup()
    } else if (randomiseVariable == "bpPresence"){
      sample.id <-  dplyr::filter(dataset, subid %in% id.index) %>%  dplyr::filter(timeSeries < mov.dur) %>%  dplyr::group_by(grain, movieName) %>%  dplyr::mutate(subject.bp.rand = sample(subject.bp)) %>% ungroup()
    }
    sample.id$newid <- i
    data.df <- rbind(data.df, sample.id)
  }
  return(data.df)
}

```

**Load files** 
Load segmentation data -> this datasets contain participants' button press times. 
Standardize the variable names across comm and evAct datasets

```{r loadSegmentationData}
setwd('../data/raw')
segment.data.commercial <- read.delim("esMethods_Commercial_SegmentData.txt", head = TRUE)
segment.data.commercial$subid[segment.data.commercial$condition == "Ordered"] <- segment.data.commercial$subid[segment.data.commercial$condition == "Ordered"] + 35 
segment.data.evAct <- read.delim("esMethods_EvAct_SegmentData.txt", head = TRUE)
names(segment.data.evAct)[names(segment.data.evAct) == "movie"] <- "movieName"
names(segment.data.evAct)[names(segment.data.evAct) == "time"] <- "bpTime"
```

 Because our analyses involve comparisons between different movies, we will utilise a portion of each dataset, following the shortest movie duration.  -->
```{r truncateData}
movieDur.commercial = 566 #duration of shortest commercial movie (in seconds)
segment.data.commercial <- segment.data.commercial %>% filter(bpTime < movieDur.commercial)
movieDur.evAct = 273 #duration of shortest everyday activity videos (in seconds)
segment.data.evAct <- segment.data.evAct %>% filter(bpTime < movieDur.evAct)
```

**Peak to peak distance.**
Peak to peak distance measures how far apart are two independent groups' (sample and test group) boundary placement in time. This measure is calculated by first estimating the density distributions of each group's segmentation data. We then extract timepoints of the highest density for each group, creating an array of peak times.For both groups, the amount of peak times extracted is based on the average number of boundaries identified by the sample group. We subtract each sample's peak time with the test group's peaktime of the nearest value. We repeat this process one more time, subtracting each test group's peak time with the sample's nearest peak times. The average of these difference values is the resultant peak to peak distance. 

*Commercial*
```{r getEssentials_commercial}
movieDur <- 566 
movieNames <- as.character(unique(segment.data.commercial$movieName))
segmentGrains <- as.character(unique(segment.data.commercial$grain))
```

```{r peaktopeakdistance_commercial}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(segment.data.commercial$subid)
#Resultant density bandwidth = bw*adj.size
bw = 'sj' #Recommended by R is 'sj' -> minimises mean integrated squared error
###
sample.types <- c("sample", "random", "crossMov")
nearestDistance <- data.frame()

for (it in iterations){
  for (s.size in sample.sizes){
    sample.subid <- sample(subjects, size = s.size, replace = TRUE)
    test.subid <- sample(subjects[!subjects %in% sample.subid], size = s.size, replace = TRUE)
    sample.data <- get.sample.dataset(sample.subid, segment.data.commercial, "bpTime", movieDur)
    test.data <- get.sample.dataset(test.subid, segment.data.commercial, "bpTime", movieDur)
    for (movie in movieNames){
      crossMovie <- movieNames[movieNames!=movie]
      for(segmentGrain in segmentGrains){
        if (segmentGrain == 'c'){
          adj.size = 0.1
        } else {
          adj.size = 0.05
        }
        dt.sample <- sample.data %>% dplyr::filter(movieName == movie, grain == segmentGrain)
        dt.test <- test.data %>% dplyr::filter(movieName == movie, grain == segmentGrain)
        dt.crossMov <- sample.data %>% dplyr::filter(movieName == crossMovie, grain == segmentGrain)
        
        ave.bp = dt.sample %>% dplyr::group_by(newid) %>% dplyr::summarise(bp.no = length(bpTime)) %>% dplyr::summarise(bp = mean(bp.no))
        
        near.dist.sample <- get.peaktopeak.distance(dt.sample$bpTime, dt.test$bpTime, movieDur, adj.size, ave.bp$bp, bw)
        near.dist.random <- get.peaktopeak.distance(dt.sample$bpTime.rand, dt.test$bpTime.rand, movieDur, adj.size, ave.bp$bp, bw)
        near.dist.crossMov <- get.peaktopeak.distance(dt.crossMov$bpTime, dt.test$bpTime, movieDur, adj.size, ave.bp$bp, bw)
        
        for (sample.type in sample.types){
          assign("near.dist", get(paste("near.dist.", sample.type, sep = "")))
          nearestDistance <- rbind(nearestDistance, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, nearestDistance = near.dist$nearestDistance, nPeak_sample = near.dist$sample_nPeaks, ave_samplePeakInterval = near.dist$ave_samplePeakInterval, sd_samplePeakInterval = near.dist$sd_samplePeakInterval, nPeak_test = near.dist$test_nPeaks, ave_testPeakInterval = near.dist$ave_testPeakInterval, sd_testPeakInterval = near.dist$sd_testPeakInterval))
        }
      }
    }
  }
  print(it)
}

#plot figure to check trend 
peaktopeak.comm.plot <- plotAgreementValues(nearestDistance, "nearestDistance", "Peak-to-peak distance(s)")
peaktopeak.comm.plot

# setwd('../data/bootstrapped')
# write.table(nearestDistance,"esMethods_PeakPeakDistance_c0.1_f0.05_100Iterations_commercial.txt", sep="\t",row.names=FALSE)
```

Calculate average button press bootstrapped data from n.iterations times of each sample size 
```{r average button press_commercial}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(segment.data.commercial$subid)
#Resultant density bandwidth = bw*adj.size
bw = 'sj' #Recommended by R is 'sj' -> minimises mean integrated squared error
###
sample.types <- c("sample", "random", "crossMov")
average.bp <- data.frame()

for (it in iterations){
  for (s.size in sample.sizes){
    sample.subid <- sample(subjects, size = s.size, replace = TRUE)
    test.subid <- sample(subjects[!subjects %in% sample.subid], size = s.size, replace = TRUE)
    sample.data <- get.sample.dataset(sample.subid, segment.data.commercial, "bpTime", movieDur)
    test.data <- get.sample.dataset(test.subid, segment.data.commercial, "bpTime", movieDur)
    for (movie in movieNames){
      for(segmentGrain in segmentGrains){
        if (segmentGrain == 'c'){
          adj.size = 0.1
        } else {
          adj.size = 0.05
        }
        dt.sample <- sample.data %>% dplyr::filter(movieName == movie, grain == segmentGrain)
        
        ave.bp = dt.sample %>% dplyr::group_by(newid) %>% dplyr::summarise(bp.no = length(bpTime)) %>% dplyr::summarise(bp = mean(bp.no))
        average.bp <- rbind(average.bp, data.frame('iteration' = it, 'sampleSize'= s.size, 'grain' = segmentGrain, 'movie' = movie, 'ave.bp' = ave.bp$bp))
      }
    }
  }
  print(it)
}

ave.bp <- average.bp %>% group_by(sampleSize, grain, movie) %>% dplyr::summarise(mean.bp = mean(ave.bp))


```

*Everyday activities* 

```{r getEssentials_evAct}
movieDur <- 273 
movieNames <- as.character(unique(segment.data.evAct$movieName))
segmentGrains <- as.character(unique(segment.data.evAct$grain))
```

```{r peaktopeakdistance_evAct}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(segment.data.evAct$subid)
#adj.size = 1 #size for density width adjustment (based on density function)
bw = 1
sample.types <- c("sample", "random", "crossMov")
nearestDistance <- data.frame()

for (it in iterations){
  for (movie in movieNames){
    crossMovies <- movieNames[movieNames!=movie]
    subjects.sameMov <- unique(segment.data.evAct$subid[segment.data.evAct$movieName == movie])
    for (s.size in sample.sizes){
      #select subject ids to make up sample dataset 
      sample.subid <- sample(subjects.sameMov, size = s.size, replace = TRUE)
      
      #select subject ids to make up test dataset, with participants not including those in sample dataset
      test.subid <- sample(subjects.sameMov[!subjects.sameMov %in% sample.subid], size = s.size, replace = TRUE)
      
      #filter dataset to include selected subjects for both sample and test data 
      sample.data <- get.sample.dataset(sample.subid, segment.data.evAct, "bpTime", movieDur)
      test.data <- get.sample.dataset(test.subid, segment.data.evAct, "bpTime", movieDur)
      for (segmentGrain in segmentGrains){
        if (segmentGrain == "c"){
          adj.size = 0.1
        } else {
          adj.size = 0.05
        }
        
        #filter sample and test dataset for movie and grain
        dt.sample <- sample.data %>% filter(movieName == movie, grain == segmentGrain)
        dt.test <- test.data %>% filter(movieName == movie, grain == segmentGrain)
        
        #calculate the average button press of sample dataset
        ave.bp <- dt.sample %>% group_by(newid) %>% dplyr::summarise(bp.no = length(bpTime)) %>% dplyr::summarise(bp = mean(bp.no))
        
        #get nearest peak to peak distance
        near.dist.sample <- get.peaktopeak.distance(dt.sample$bpTime, dt.test$bpTime, movieDur, adj.size, ave.bp$bp, bw)
        near.dist.random <- get.peaktopeak.distance(dt.sample$bpTime.rand, dt.test$bpTime.rand, movieDur, adj.size, ave.bp$bp, bw)
        
        #calculate the nearest distance when sample is compared with segmentation of all other movies of the same sample size. 
        neardist.crossMov <- data.frame()
        for (crossMov in crossMovies){
          subjects.crossMov <- unique(segment.data.evAct$subid[segment.data.evAct$movieName == crossMov])
          crossMov.subid <- sample(subjects.crossMov, size = s.size, replace = TRUE)
          crossMov.data <- get.sample.dataset(crossMov.subid, segment.data.evAct, "bpTime", movieDur)
          dt.crossMov <- crossMov.data %>% filter(movieName == crossMov, grain == segmentGrain)
          neardist.crossMov <- rbind(neardist.crossMov, get.peaktopeak.distance(dt.sample$bpTime, dt.crossMov$bpTime, movieDur, adj.size, ave.bp$bp, bw)) 
        }
        near.dist.crossMov <- as.data.frame.list(colMeans(neardist.crossMov))
        
        #Put nearest distance into dataframes for saving 
        for (sample.type in sample.types){
          assign("near.dist", get(paste("near.dist.", sample.type, sep = "")))
          nearestDistance <- rbind(nearestDistance, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, nearestDistance = near.dist$nearestDistance, nPeaks_sample = near.dist$sample_nPeaks, ave_samplePeakInterval = near.dist$ave_samplePeakInterval, sd_samplePeakInterval = near.dist$sd_samplePeakInterval, mPeaks_test = near.dist$test_nPeaks, ave_testPeakInterval = near.dist$ave_testPeakInterval, sd_testPeakInterval = near.dist$sd_testPeakInterval))
      }
      
     }
    }
  }
  print(it)
}

peaktopeak.evAct.plot <- plotAgreementValues(nearestDistance, "nearestDistance", "Peak-to-peak distance (s)")
  
# setwd('../data/bootstrapped')
# write.table(nearestDistance,"esMethods_PeakPeakDistance_c0.1_f0.05_100Iterations_evAct.txt", sep="\t",row.names=FALSE)
```

**Peakiness**
Peakiness represents the degree of group agreement on both boundary and non-boundary periods throughout the duration of the movie. Peakiness is measured by calculating rugosity - a measure of surface roughness typically used by marine biologist to measure the contours of coral reef. Broadly, peakiness is calculated by measuring the total length of the segmentation density distribution, following its contours (i.e. end to end distance following every peak and trough) over the total duration of the movie. This peakiness value is then divided with the minimum peakiness (when group button press is distributed uniformly over movie length). 


*commercial films*
```{r getEssentials_commercial}
movieDur <- 566 
movieNames <- as.character(unique(segment.data.commercial$movieName))
segmentGrains <- as.character(unique(segment.data.commercial$grain))
```

```{r peakiness_commercial}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(segment.data.commercial$subid[segment.data.commercial$condition == "Full"]) #pooling subjects from "Full" condition only 
bw = 'sj'
sample.types <- c("sample", "random")
peakiness <- data.frame()

for (it in iterations){
  for (s.size in sample.sizes){
    sample.subid <- sample(subjects, size = s.size, replace = TRUE)
    sample.data <- get.sample.dataset(sample.subid, segment.data.commercial, "bpTime", movieDur)
    for (movie in movieNames){
      for(segmentGrain in segmentGrains){
        if(segmentGrain == 'c'){
          adj.size = 0.1
        } else {
          adj.size = 0.05
        }
        dt.sample <- sample.data %>% filter(movieName == movie, grain == segmentGrain)
        
        rugo.sample <- get.peakiness(dt.sample$bpTime, movieDur, dt.sample$subid, adj.size, bw)
        rugo.random <- get.peakiness(dt.sample$bpTime.rand, movieDur, dt.sample$subid, adj.size, bw)

        for (sample.type in sample.types){
          assign("rugo", get(paste("rugo.", sample.type, sep = "")))
          peakiness <- rbind(peakiness, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, min.peakiness = rugo[1], act.peakiness = rugo[2]))
        }
      }
    }
  }
  print(it)
}

peakiness.comm.plot <- plotAgreementValues(peakiness, "act.peakiness", "Peakiness")
peakiness.comm.plot
# setwd('../data/bootstrapped')
# write.table(peakiness,"esMethods_Peakiness_adjust_c0.1_f0.05_100Iterations_commercial.txt", sep="\t",row.names=FALSE)
```

*Everyday activities*

```{r getEssentials_commercial}
movieDur <- 273 
movieNames <- as.character(unique(segment.data.evAct$movieName))
segmentGrains <- as.character(unique(segment.data.evAct$grain))
```

```{r peakiness_evAct}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(segment.data.evAct$subid)
bw = 'sj'
sample.types <- c("sample", "random")
peakiness <- data.frame()

for (it in iterations){
  for (movie in movieNames){
    subjects.sameMov <- unique(segment.data.evAct$subid[segment.data.evAct$movieName == movie])
    for (s.size in sample.sizes){
      #select subject ids to make up sample dataset 
      sample.subid <- sample(subjects.sameMov, size = s.size, replace = TRUE)
      
      #filter dataset to include selected subjects for both sample and test data 
      sample.data <- get.sample.dataset(sample.subid, segment.data.evAct, "bpTime", movieDur)
      for (segmentGrain in segmentGrains){
        if (segmentGrain == 'c'){
          adj.size = 0.1
        } else {
          adj.size = 0.05
        }
        
        #filter sample and test dataset for movie and grain
        dt.sample <- sample.data %>% filter(movieName == movie, grain == segmentGrain)
        
        #get nearest peak to peak distance
        rugo.sample <- get.peakiness(dt.sample$bpTime, movieDur, dt.sample$subid, adj.size,bw)
        rugo.random <- get.peakiness(dt.sample$bpTime.rand, movieDur, dt.sample$subid, adj.size,bw)
        
        #Put nearest distance into dataframes for saving 
        for (sample.type in sample.types){
          assign("rugo", get(paste("rugo.", sample.type, sep = "")))
          peakiness <- rbind(peakiness, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, min.peakiness = rugo[1], act.peakiness = rugo[2]))
      }
      
     }
    }
  }
  print(it)
}

peakiness.evAct.plot <- plotAgreementValues(peakiness, "act.peakiness", "Peakiness")
peakiness.evAct.plot

# setwd('../data/bootstrapped')
# write.table(peakiness,"esMethods_Peakiness_adjust_c0.1_f0.05_100Iterations_evAct.txt", sep="\t",row.names=FALSE)
```

The subsequent two metrices: agreement and surprise index will utilise data that is structured as timeseries of button presses. These time series contain presence(1) or absence (0) of button press at every 1 second interval. 

*Load timeseries dataset*
```{r loadTimeseries}
setwd('../data/raw')
ts.data.commercial <- read.delim("esMethods_Commercial_TimeSeries.txt", head = TRUE)
ts.data.evAct <- read.delim("esMethods_EvAct_TimeSeries.txt", head = TRUE)
names(ts.data.commercial)[names(ts.data.commercial) == "movName"] <- "movieName"
names(ts.data.evAct)[names(ts.data.evAct) == "movName"] <- "movieName"
```

**Agreement Index**

Agreement index measures the correlation between individual segmentation behaviour with the rest of the sample (Zacks et al., 2006). Each subject's segmentation data were converted into a time series binned every 1 second. For each second, presence of button press was coded as 1 and absence of button press was coded as 0. For the remaining group's segmentation data, each second of the time series would contain the proportion of participants who coded that second as containing a boundary. Correlation between each participant's timeseries with the rest of the sample were correlated and divided by the difference between the maximum and minimum correlation possible (to control for individual's number of button press). Maximum correlation was calculate by ordering both participant's and rest of group's timeseries in descending order and then computing the correlation (perfect correlation). Minimum correlaion was calculated by ordering participant's timeseries in descending order while ordering the group's timeseries in ascending order and then computing the correlation (perfect anti-correlation). 


*Commercial movies*

```{r getEssentials_commercial}
movieDur <- 566 
movieNames <- as.character(unique(segment.data.commercial$movieName))
segmentGrains <- as.character(unique(segment.data.commercial$grain))
```


```{r agreementIndex_commercial}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(ts.data.commercial$subid[ts.data.commercial$condition == "Full"])
sample.types <- c("sample", "random", "crossMov")
agreement.index <- data.frame()

for (it in iterations){
  for (s.size in sample.sizes){
    sample.subid <- sample(subjects, size = s.size, replace = TRUE)
    sample.data <- get.sample.dataset(sample.subid, ts.data.commercial, "bpPresence", movieDur)
    for (movie in movieNames){
      crossMovie <- movieNames[movieNames!=movie]
      for(segmentGrain in segmentGrains){
        #filter datasets for based on movie and grain
        dt.sample <- sample.data %>% filter(movieName == movie, grain == segmentGrain)
        dt.crossMov <- sample.data %>% filter(movieName == crossMovie, grain == segmentGrain)
        
        #create empty variables for agreement index of each subject in dt
        agreement.sample <- NULL
        agreement.random <- NULL
        agreement.crossMov <- NULL
        for (subject in unique(dt.sample$newid)){
          
          #calculate agreement index for subject and rest of sample 
          subject.ts <- dt.sample$subject.bp[dt.sample$newid == subject]
          group.ts <- dt.sample %>% filter(newid != subject) %>% group_by(timeSeries) %>% summarise(gp.bp = mean(subject.bp))
          agreement.sample <- rbind(agreement.sample, get.agreement.index(subject.ts, group.ts$gp.bp))
          
          #calculate agreement index for subject's random segmentation with sample's random segmentation
          subject.rand.ts <- dt.sample$subject.bp.rand[dt.sample$newid == subject]
          group.rand.ts <- dt.sample %>% filter(newid != subject) %>% group_by(timeSeries) %>% summarise(gp.bp = mean(subject.bp.rand))
          agreement.random <- rbind(agreement.random, get.agreement.index(subject.rand.ts, group.rand.ts$gp.bp))
          
          #calculate agreement index for subject's segmentation vs sample's segmentation of the other movie
          crossMov.ts <- dt.crossMov %>% group_by(timeSeries) %>% summarise(gp.bp = mean(subject.bp))
          agreement.crossMov <- rbind(agreement.crossMov, get.agreement.index(subject.ts, crossMov.ts$gp.bp))
        }
        #average agreement index and organise in dataframe
        for (sample.type in sample.types){
          assign("agreement", get(paste("agreement.", sample.type, sep = "")))
          agreement.index <- rbind(agreement.index, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, minCorrelation = mean(agreement[,1]), maxCorrelation = mean(agreement[,2]), actCorrelation = mean(agreement[,3]), agreementIndex = mean(agreement[,4])))
        }
      }
    }
  }
  print(it)
}

agreement.comm.plot <- plotAgreementValues(agreement.index, "agreementIndex", "Agreement Index")
agreement.comm.plot

# setwd('../data/bootstrapped')
# write.table(agreement.index,"esMethods_AgreementIndex_100Iterations_commercial.txt", sep="\t",row.names=FALSE)

```

*Everyday activities*

```{r getEssentials_evAct}
movieDur <- 273 
movieNames <- as.character(unique(ts.data.evAct$movieName))
segmentGrains <- as.character(unique(ts.data.evAct$grain))
```

```{r peaktopeakdistance_evAct}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(segment.data.evAct$subid)
sample.types <- c("sample", "random", "crossMov")
#agreement.index <- data.frame()

for (it in iterations){
  for (movie in movieNames){
    crossMovies <- movieNames[movieNames!=movie]
    subjects.sameMov <- unique(ts.data.evAct$subid[ts.data.evAct$movieName == movie])
    for (s.size in sample.sizes){
      #select subject ids to make up sample dataset 
      sample.subid <- sample(subjects.sameMov, size = s.size, replace = TRUE)
      
      #filter dataset to include selected subjects for both sample and test data 
      sample.data <- get.sample.dataset(sample.subid, ts.data.evAct, "bpPresence", movieDur)
      
      for (segmentGrain in segmentGrains){
        #filter sample and test dataset for movie and grain
        ts.sample <- sample.data %>% filter(movieName == movie, grain == segmentGrain)

        agreement.sample <- NULL
        agreement.random <- NULL
        agreement.crossMov <- NULL
        for (subject in unique(ts.sample$newid)){
          
          #calculate agreement index for subject and rest of sample 
          subject.ts <- ts.sample$subject.bp[ts.sample$newid == subject]
          group.ts <- ts.sample %>% dplyr::filter(newid != subject) %>% dplyr::group_by(timeSeries) %>% dplyr::summarise(gp.bp = mean(subject.bp))
          agreement.sample <- rbind(agreement.sample, get.agreement.index(subject.ts, group.ts$gp.bp))
          
          #calculate agreement index for subject's random segmentation with sample's random segmentation
          subject.rand.ts <- ts.sample$subject.bp.rand[ts.sample$newid == subject]
          group.rand.ts <- ts.sample %>% dplyr::filter(newid != subject) %>% dplyr::group_by(timeSeries) %>% dplyr::summarise(gp.bp = mean(subject.bp.rand))
          agreement.random <- rbind(agreement.random, get.agreement.index(subject.rand.ts, group.rand.ts$gp.bp))
          
          #calculate agreement index for subject's segmentation vs sample's segmentation of the other movie
          crossMov.ai <- NULL
          for (crossMovie in crossMovies){
            subjects.crossMov <- unique(ts.data.evAct$subid[ts.data.evAct$movieName == crossMovie])
            crossMov.subid <- sample(subjects.crossMov, size = s.size, replace = TRUE)
            crossMov.data <- get.sample.dataset(crossMov.subid, ts.data.evAct, "bpPresence", movieDur)
            crossMov.ts <- crossMov.data %>% dplyr::filter(movieName == crossMovie, grain == segmentGrain) %>% dplyr::group_by(timeSeries) %>% dplyr::summarise(bp = mean(subject.bp))
            
            crossMov.ai <- rbind(crossMov.ai, get.agreement.index(subject.ts, crossMov.ts$bp))
          }
          agreement.crossMov <- rbind(agreement.crossMov, colMeans(x = crossMov.ai))
        }
        
        #average agreement index and organise it in dataframe 
        for (sample.type in sample.types){
          assign("agreement", get(paste("agreement.", sample.type, sep = "")))
          agreement.index <- rbind(agreement.index, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, minCorrelation = mean(agreement[,1]), maxCorrelation = mean(agreement[,2]), actCorrelation = mean(agreement[,3]), agreementIndex = mean(agreement[,4])))
      }
      
     }
    }
  }
  print(it)
}

agreement.evAct.plot <- plotAgreementValues(agreement.index, "agreementIndex", "Agreement Index")
agreement.evAct.plot 
# setwd('../data/bootstrapped')
# write.table(agreement.index,"esMethods_AgreementIndex_100Iterations_evAct.txt", sep="\t",row.names=FALSE)
```


**Surprise Index**

Surprise represents how often do individual's boundary identification coincides with the rest of the group's. This measure is adapted from Katori et al., 2018. First for one participant, we calculate the frequency of overlap between participant's button press time with the rest of the sample's button press times (n). Rest of samples button press times is calculated by first calculating the density estimate of the group's button button press and extracting the times of n-highest density values, where n = average number of button press for the group. 
Next we calculate the expected value of button press overlap between individual to the rest of sample: 
Poverlap = e^-(lambda)*(lambda/n!)
Where lambda = frequency of individual segmentation x frequency of rest of sample segmentation x number of bins (movie duration)

Surprise index is then calculated as: -log2*Poverlap

*Commercial movies*

```{r getEssentials_commercial}
movieDur <- 566 
movieNames <- as.character(unique(ts.data.commercial$movieName))
segmentGrains <- as.character(unique(ts.data.commercial$grain))
```

```{r surpriseIndex_commercial}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(ts.data.commercial$subid[ts.data.commercial$condition == "Full"])
sample.types <- c("sample", "random", "crossMov")
surprise.index <- data.frame()
bw = 'sj'

for (it in iterations){
  for (s.size in sample.sizes){
    sample.subid <- sample(subjects, size = s.size, replace = TRUE)
    sample.data <- get.sample.dataset(sample.subid, segment.data.commercial, "bpTime", movieDur)
    for (movie in movieNames){
      crossMovie <- movieNames[movieNames!=movie]
      for(segmentGrain in segmentGrains){
        if(segmentGrain == 'c'){
          adj.size = 0.1
        } else {
          adj.size = 0.05
        }
        #filter datasets for based on movie and grain
        dt.sample <- sample.data %>% filter(movieName == movie, grain == segmentGrain)
        dt.crossMov <- sample.data %>% filter(movieName == crossMovie, grain == segmentGrain)
        
        #create empty variables for agreement index of each subject in dt
        surprise.sample <- NULL
        surprise.random <- NULL
        surprise.crossMov <- NULL
        for (subject in unique(dt.sample$newid)){
          
          #calculate surprise index for subject and rest of sample 
          subject.bp <- dt.sample %>% dplyr::filter(newid == subject) %>% dplyr::select(bpTime)
          sub.bp <- unique(floor(subject.bp$bpTime))
          group.bp <- dt.sample %>% dplyr::filter(newid != subject) %>% dplyr::select(bpTime)
          ave.bp <- dt.sample %>% dplyr::filter(newid != subject) %>% dplyr::group_by(newid) %>% dplyr::summarise(bp = length(bpTime)) %>% dplyr::summarise(ave.bp = mean(bp))
          surprise.sample <- rbind(surprise.sample, get.surprise.index(sub.bp, group.bp$bpTime, movieDur, ave.bp$ave.bp, bw, adj.size))
          
          #calculate surprise index for subject's random segmentation with sample's random segmentation
          subject.rand.bp <-dt.sample %>% dplyr::filter(newid == subject) %>% dplyr::select(bpTime.rand)
          sub.bp.rand <- unique(floor(subject.rand.bp$bpTime.rand))
          group.rand.bp <- dt.sample %>% dplyr::filter(newid != subject) %>% dplyr::select(bpTime.rand)
          surprise.random <- rbind(surprise.random, get.surprise.index(sub.bp.rand, group.rand.bp$bpTime.rand, movieDur, ave.bp$ave.bp, bw, adj.size))
          
          #calculate agreement index for subject's segmentation vs sample's segmentation of the other movie
          crossMov.bp <- dt.crossMov %>% dplyr::select(bpTime)
          ave.bp.crossMov <- dt.crossMov %>% dplyr::group_by(newid) %>% dplyr::summarise(bp = length(bpTime)) %>% dplyr::summarise(ave.bp = mean(bp))
          surprise.crossMov <- rbind(surprise.crossMov, get.surprise.index(sub.bp, crossMov.bp$bpTime, movieDur, ave.bp.crossMov$ave.bp, bw, adj.size))
        }
        #average agreement index and organise in dataframe
        for (sample.type in sample.types){
          assign("surprise", get(paste("surprise.", sample.type, sep = "")))
          surprise.index <- rbind(surprise.index, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, surpriseIndex = mean(surprise)))
        }
      }
    }
  }
  print(it)
}

surprise.comm.plot <- plotAgreementValues(surprise.index, "surpriseIndex", "Surprise Index")
surprise.comm.plot

# setwd('../data/bootstrapped')
# write.table(surprise.index,"esMethods_SurpriseIndex_c0.1_f0.05_100Iterations_commercial.txt", sep="\t",row.names=FALSE)
```


*Everyday activities*

```{r getEssentials_everydayActivities}
movieDur <- 273 
movieNames <- as.character(unique(ts.data.evAct$movieName))
segmentGrains <- as.character(unique(ts.data.evAct$grain))
```

```{r surpriseIndex_everydayActivities}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
sample.types <- c("sample", "random", "crossMov")
surprise.index <- data.frame()

for (it in iterations){
  for (movie in movieNames){
    crossMovies <- movieNames[movieNames!=movie]
    subjects.sameMov <- unique(ts.data.evAct$subid[ts.data.evAct$movieName == movie])
    for (s.size in sample.sizes){
      #select subject ids to make up sample dataset 
      sample.subid <- sample(subjects.sameMov, size = s.size, replace = TRUE)
      
      #filter dataset to include selected subjects for both sample and test data 
      sample.data <- get.sample.dataset(sample.subid, segment.data.evAct, "bpTime", movieDur)
      
      for (segmentGrain in segmentGrains){
        if (segmentGrain == 'c'){
          adj.size = 0.1
        } else {
          adj.size = 0.05
        }
        #filter sample and test dataset for movie and grain
        ts.sample <- sample.data %>% filter(movieName == movie, grain == segmentGrain)

        surprise.sample <- NULL
        surprise.random <- NULL
        surprise.crossMov <- NULL
        for (subject in unique(ts.sample$newid)){
          
          #calculate surprise index for subject and rest of sample 
          subject.bp <- ts.sample$bpTime[ts.sample$newid == subject]
          sub.bp <- unique(floor(subject.bp))
          group.bp <- ts.sample %>% dplyr::filter(newid != subject) %>% dplyr::select(bpTime)
          ave.bp <- ts.sample %>% dplyr::filter(newid != subject) %>% dplyr::group_by(newid) %>% dplyr::summarise(bp = length(bpTime)) %>% summarise(ave.bp = mean(bp))
          surprise.sample <- rbind(surprise.sample, get.surprise.index(sub.bp, group.bp$bpTime, movieDur, ave.bp$ave.bp, bw, adj.size))
          
          #calculate surprise index for subject's random segmentation with sample's random segmentation
          subject.rand.bp <- ts.sample$bpTime.rand[ts.sample$newid == subject]
          sub.bp.rand <- unique(floor(subject.rand.bp))
          group.rand.bp <- ts.sample %>% dplyr::filter(newid != subject) %>% dplyr::select(bpTime.rand)
          surprise.random <- rbind(surprise.random, get.surprise.index(sub.bp.rand, group.rand.bp$bpTime.rand, movieDur, ave.bp$ave.bp, bw, adj.size))
          
          #calculate surprise index for subject's segmentation vs sample's segmentation of the other movie
          crossMov.si <- NULL
          for (crossMovie in crossMovies){
            subjects.crossMov <- unique(ts.data.evAct$subid[ts.data.evAct$movieName == crossMovie])
            crossMov.subid <- sample(subjects.crossMov, size = s.size, replace = TRUE)
            crossMov.data <- get.sample.dataset(crossMov.subid, segment.data.evAct, "bpTime", movieDur)
            crossMov.bp <- crossMov.data %>% dplyr::filter(movieName == crossMovie, grain == segmentGrain) %>% dplyr::select(bpTime)
            ave.bp.crossMov <- crossMov.data %>% dplyr::filter(movieName == crossMovie, grain == segmentGrain) %>% group_by(newid) %>% dplyr::summarise(bp = length(bpTime)) %>% dplyr::summarise(ave.bp = mean(bp))
            
            crossMov.si <- rbind(crossMov.si, get.surprise.index(sub.bp, crossMov.bp$bpTime, movieDur, ave.bp.crossMov$ave.bp, bw, adj.size))
          }
          surprise.crossMov <- rbind(surprise.crossMov, colMeans(x = crossMov.si))
        }
        
        #average surprise index and organise it in dataframe 
        for (sample.type in sample.types){
          assign("surprise", get(paste("surprise.", sample.type, sep = "")))
          surprise.index <- rbind(surprise.index, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, surpriseIndex = mean(surprise)))
      }
      
     }
    }
  }
  print(it)
}

surprise.evAct.plot <- plotAgreementValues(surprise.index, "surpriseIndex", "Surprise Index")
surprise.evAct.plot
  
# setwd('../data/bootstrapped')
# write.table(surprise.index,"esMethods_SurpriseIndex_c0.1_f0.05_100Iterations_evAct.txt", sep="\t",row.names=FALSE)
```

**Generate parameters necessary for subsequent calculation of predictive value and detection accuracy** 

To calculate predictive value and detection accuracy, need to generate: 
1. normativeHit = hit rate (proportion of indiv button press overlapping with normative boundary) 
2. normativeFA = false alarm rate (proportion of indiv button press non-overlapping with non-normative boundary)
3. normativeMiss = misses (proportion of indiv button press non-overlapping with normavie boundary)
4. normativeCR = correct rejection (proportion of indiv bon button press overlapping with non-normative boundary)
5. normativePPV = positive predictive value (indiv button press overlap with normative boundary/total indiv bp times)
6. normativeFalsePPV = indiv button press overlap with non normative boundary / total indiv bp times

Predictive accuracy will then be calculated as: qnorm(normativePPV) - qnorm(normativeFalsePPV)
Detection accuracy will then be calculated as:  qnorm(normativeHit) - qnorm(normativeFA)

*Commercial movies*

```{r getEssentials_commercial}
movieDur <- 566 
movieNames <- as.character(unique(ts.data.commercial$movieName))
segmentGrains <- as.character(unique(ts.data.commercial$grain))
```


```{r normativeHitRate_commercial_normativeBinnedBoundary}
iterations = seq(from = 1, to = n.iterations, by = 1)
sample.sizes = seq(from = sampleSize.min, to = sampleSize.max, by = sampleSize.interval)
subjects = unique(ts.data.commercial$subid[ts.data.commercial$condition == "Full"])
sample.types <- c("sample", "random", "crossMov")
normative.hitRate <- data.frame()

for (it in iterations){
  for (s.size in sample.sizes){
    sample.subid <- sample(subjects, size = s.size, replace = TRUE)
    sample.data <- get.sample.dataset(sample.subid, ts.data.commercial, "bpPresence", movieDur)
    for (movie in movieNames){
      crossMovie <- movieNames[movieNames!=movie]
      for(segmentGrain in segmentGrains){
        #filter datasets for based on movie and grain
        dt.sample <- sample.data %>% dplyr::filter(movieName == movie, grain == segmentGrain)

        dt.crossMov <- sample.data %>% dplyr::filter(movieName == crossMovie, grain == segmentGrain)

        #create empty variables for normative hit rate of each subject in dt
        normativeHit.sample <- NULL
        normativeHit.random <- NULL
        normativeHit.crossMov <- NULL
        timeSeries <- unique(dt.sample$timeSeries)
        for (subject in unique(dt.sample$newid)){
          
          #calculate agreement index for subject and rest of sample 
          subject.ts <- dt.sample$subject.bp[dt.sample$newid == subject]
          group.data <- dt.sample %>% dplyr::filter(newid != subject) 
          group.ts <- group.data %>% dplyr::group_by(timeSeries) %>% dplyr::summarise(group.bp = mean(subject.bp))

          ave.bp <- group.data %>% dplyr::group_by(newid) %>% dplyr::summarise(bp = sum(subject.bp)) %>% dplyr::summarise(mean = mean(bp))
          normativeHit.sample <- rbind(normativeHit.sample, get.normative.hitRate_bin(subject.ts, group.ts, ave.bp$mean, timeSeries))

          #calculate agreement index for subject's random segmentation with sample's random segmentation
          subject.rand.ts <- dt.sample$subject.bp.rand[dt.sample$newid == subject]
          group.ts.rand <- group.data %>% dplyr::group_by(timeSeries) %>% dplyr::summarise(group.bp = mean(subject.bp.rand))
          normativeHit.random <- rbind(normativeHit.random, get.normative.hitRate_bin(subject.ts, group.ts.rand, ave.bp$mean, timeSeries))

          #calculate agreement index for subject's segmentation vs sample's segmentation of the other movie
          ave.bp.crossMov <- dt.crossMov %>% dplyr::group_by(newid) %>% dplyr::summarise(bp = sum(subject.bp)) %>% dplyr::summarise(mean = mean(bp))
          crossMov.ts <- dt.crossMov %>% dplyr::group_by(timeSeries) %>% dplyr::summarise(group.bp = mean(subject.bp))
          normativeHit.crossMov <- rbind(normativeHit.crossMov, get.normative.hitRate_bin(subject.ts, crossMov.ts, ave.bp.crossMov$mean, timeSeries))
        }
        #average agreement index and organise in dataframe
        for (sample.type in sample.types){
          assign("normativeHit", get(paste("normativeHit.", sample.type, sep = "")))
          normative.hitRate <- rbind(normative.hitRate, data.frame(Iteration = it, sampleSize = s.size, movieName = movie, grain = segmentGrain, testCond = sample.type, normativeHit = mean(normativeHit$normativeHit), normativeFA = mean(normativeHit$normativeFA), normativeMiss = mean(normativeHit$normativeMiss), normativeCR = mean(normativeHit$normativeCR), normativePPV = mean(normativeHit$normativePPV), normativeFalsePPV = mean(normativeHit$normativeFalsePPV)))
        }
      }
    }
  }
  print(it)
}

hitRate.plot <- plotAgreementValues(normative.hitRate, "normativeHit", "Hit rate")
hitRate.plot

#setwd('../data/bootstrapped')
#write.table(normative.hitRate,"esMethods_normativeHitRate_bin_100Iterations_commercial.txt", sep="\t",row.names=FALSE)

```





